layout: post
title: "DockerizeMe:Python代码片段依赖环境自动分析工具"
date: 2019-10-17 
description: "DockerizeMe"
tags: paper

---  

> &emsp;&emsp;像Stack Overflow和GitHub的gist系统这样的平台，通过展示用于说明特定任务的代码片段，促进思想和编程技术的共享。Python是一种流行且快速发展的编程语言，在这两个站点上都有大量的使用，Stack Overflow上有近100万个问题，GitHub上有40万个公共仓库。不幸的是，通过这些站点共享的Python示例代码中有75%不能直接执行。当在干净的环境中运行时，超过50%的公共Python仓库会由于库的导入错误而失败。

> &emsp;&emsp;我们提出了DockerizeMe，这是一种用于推断执行Python代码片段所需的依赖库的技术，使其不会出现导入错误。DockerizeMe首先从Python包索引(PyPI)获取流行Python包的资源和依赖项的离线知识。然后使用基于图的推理过程构建Docker规范。我们的推理过程解决了来自Gistable数据集的近3000个gist中的892个导入错误，其中Gistable的baseline方法无法找到并安装所有依赖项。

## 1 引言

&emsp;&emsp;在软件工程行业中，使用共享代码片段来说明特定的任务是非常普遍的[1]。由于分享例子的重要性，Stack Overflow和GitHub的gist系统等平台被创建出来，通过社区驱动的交互来促进社交学习[2]、[3]、[4]。GitHub gist是简短但完整的程序，通常只有一个文件。
 
&emsp;&emsp;不幸的是，许多代码片段并不包含正确执行所需的系统配置信息，因为系统配置不是代码的固有属性。以Sentry为例，它是一个错误报告系统。Python的官方客户端Raven支持Flask框架[5]。演示如何与Flask一起使用Sentry的例子没有描述它需要安装Flask 其他库，导致开发人员遇到运行时错误。

&emsp;&emsp;这是一个十分广泛的问题。Yang等人的研究发现，Stack Overflow中只有25%的代码片段可以在没有错误的情况下运行[3]。Horton和Parnin后来发现GitHub中24.4%的Python gist运行没有错误[6]。实验评估52.4%的gist失败原因是依赖错误。Seo等人也发现了近似50%的构建错误是由依赖项引起的[7]。此外，手动构建环境规范所涉及的工作并不简单——开发人员可能要花费20分钟到2个小时为单个代码片段创建Dockerfile，而且常常无法构建有效的规范[6]。常见的挑战包括将代码资源映射到其原始包，以及确定传递依赖项的正确安装顺序。

&emsp;&emsp;本工作的重点是自动化语言级和系统级依赖项的系统配置管理的依赖项解析过程。在执行依赖项解析之前，我们从两个源构建一个离线知识库。首先，我们通过提取声明的资源并使用动态分析来确定可能的依赖关系，处理Python包索引(PyPI)上的现有包。其次，我们检查来自GitHub的项目配置文件，并为经常一起出现的包生成关联规则。代码段的环境推理是通过查询知识库将代码资源映射到可安装包来执行的。然后，搜索算法以一致的顺序解析所有的传递依赖项。

&emsp;&emsp;我们实现了DockerizeMe，这是一个将依赖项解析应用到代码段并为相应环境生成Dockerfile的工具。与其他自动软件配置方法不同，DockerizeMe侧重于在没有外部输入的情况下推断完整的配置，而其他方法侧重于修复配置错误([8]、[9]、[10])。能够自动推断代码依赖关系可以节省开发人员的时间，降低学习和开发的成本，并在在线平台上修复和验证代码片段。这也是迈向全自动软件配置管理的第一步。

&emsp;&emsp;为了评估DockerizeMe，我们对来自Gistable数据集的2891个gist进行了环境配置，在应用了来自文献[6]III-C部分的Gistable环境推断算法之后仍然出现`ImportError`的案例，DockerizeMe成功移除了了892个导入错误。总之，这项工作包含以下贡献:
 * 提出了使用静态分析、动态分析和开发人员生成的知识源计算包依赖关系的技术。
 * 提出了遵守安装顺序的直接依赖项和传递依赖项的推理算法。
 * DockerizeMe: 推断依赖并构建环境的工具 [DockerizeMe](https://github.com/dockerizeme/dockerizeme)
 * DockerizeMe有效性的实验评估和环境配置中的额外挑战的分类。

## 2 案例与动机

&emsp;&emsp;作为示例共享的许多代码片段不是直接可执行的，这通常是因为它们依赖于外部库，而这些库在开发人员的系统上默认是不存在的[3]、[6]。发现所有必需的依赖项是一个耗时的过程，即使是经验丰富的开发人员也会有困难[6]。考虑以下场景:

&emsp;&emsp;开发人员正在处理网络组件，需要解析来自网络接口的数据包。他们希望使用Python，并搜索可用于执行此任务的Python库。幸运的是，其他开发人员以前曾要求提供关于库的建议来解决相同的问题。他们很快就会在Stack Overflow3上看到一篇文章，里面有一些不同的建议。

&emsp;&emsp;公认的答案推荐Scapy，但是它是在GPLv2下获得许可的，GPLv2是一种copyleft许可，开发人员不能在他们的项目中使用它。但是，另一个答案推荐Pcapy，并提供了一个示例代码片段，用于在数据包到达接口时打印它们。开发人员想要查看这个示例是否有效，因此他们创建了一个名为`snippet.py`的文件(图1a)包含示例代码，在示例中修改网络设备名称，将“要捕获的网络设备名称”改为“eth0”。不过，运行python代码段时,由于pcapy不是Python标准库的一部分，所以它们遇到了错误`ImportError: No moudle named pcapy`。

![Fig1](/images/posts/paper/DockerizeMe-fig1.png "Fig1 代码片段及对应的Dockerfile")

&emsp;&emsp;开发人员注意到在代码片段中导入了两个包，Pcapy和Impacket。两个包都存在于Python包索引(PyPI)，因此开发人员尝试用`pip install pcapy impacket`来安装每个包。不幸的是，由于编译器错误，Pcapy无法安装。进一步的调查显示，Pcapy依赖于开发人员没有安装的pcap系统库头文件。开发人员首先尝试使用apt-get(系统的包管理器)来安装pcap包，但是不存在这样的包。实际的包名是`libpcap0.8`。但是，pcap库没有提供Pcapy需要的头文件，开发人员发现他们必须安装开发包`libpcap-dev`。图1b中的Dockerfile对最终配置进行了编码。在没有任何帮助的情况下，开发人员在发现诸如此类的环境规范的依赖项时将面临反复试验的困难。

## 3 DockerizeMe

&emsp;&emsp;DockerizeMe的主要目的是解决软件配置管理中的依赖项解析问题。我们现在定义依赖项解析问题:给定一个可运行的代码片段C，正确安装所有语言级和系统级软件包，以便C在没有导入错误的情况下执行。语言级依赖项是由包管理器或语言运行时环境提供的工具管理的依赖项。系统级或系统依赖项安装在系统上，但在语言运行时环境的外部进行管理。

&emsp;&emsp;在依赖项解析上下文中，如果可以由执行环境评估代码段C，则认为它是可运行的。也就是说，它在编译或加载时不会出现致命错误。可运行代码段可能在运行时发生致命错误。如果由于未能找到所请求的库而导致致命的运行时错误，那么我们说C遇到了导入错误。

&emsp;&emsp;我们关注Python，这是一种流行的语言，拥有健壮的生态系统，在它的标准库平台上包含超过146,000个标准包[11]。如果Python代码段由于Python的异常`ImportError`而退出，则会遇到导入错误。我们首先通过建立离线知识库(第四和第五部分)来解决依赖项解析问题，然后设计一个推理算法(第六部分)来以可行的安装顺序返回依赖项。

&emsp;&emsp;DockerizeMe实现为一个NodeJS命令行实用程序。在Python包上运行`dockerizeme`将生成建议的Dockerfile的内容，其中包含推理过程得到的所有依赖项。

## 4 知识获取

&emsp;&emsp;DockerizeMe使用离线知识库来正确推断目标脚本的依赖关系。这个知识库包含包、它们的版本和资源，以及它们之间的关系。它是通过对库中的已知包应用静态和动态分析来构建的。输入输出数据集[12]。静态分析枚举包的已知资源以供以后检索，而动态分析则收集关于传递依赖项的信息。公共Python项目中依赖项的关联规则挖掘利用了开发人员生成的系统级传递依赖项的知识。现在我们详细讨论每种技术。

***A. 发现包资源***

&emsp;&emsp;推断哪些包对应于脚本使用的代码资源是一项具有挑战性的任务。根据[6]的报告，许多资源的名称与它们所属的包不同。开发人员通常很难确定使用哪个包。


&emsp;&emsp;为了更好地为我们的推理过程提供信息，我们分析了PyPI上的前10000个Python包，这些包基于它们在库中的源代码级别。输入输出数据集[12]。包是根据源级别来选择的，以包含最常用的库，因为流行的库可以影响包生态系统的大部分，并且生态系统的大小不允许对[13]进行全面分析。如果安装成功，我们将把发行版的顶级资源记录在top_level.txt中。例如，我们从Python包biopython中提取了Bio和BioSQL资源。88%的测试包安装成功。
&emsp;&emsp;由于缺少依赖项或其他未知的配置，有些包可能无法安装。当这种情况发生时，我们尝试手动下载和解析包发行版。使用选项——no-cache-dir和——no-deps下载所有包。如果包在PyPI上提供了一个wheel (Python二进制格式的发行版)，我们下载它时使用的是——only-binary=:all:。如果这个包在PyPI上没有轮子，但是有一个源代码发行版，我们下载它的时候使用了——no-binary=:all:。对于源发行版，我们随后尝试使用选项no-deps构建一个轮盘发行版。如果我们成功地为包下载或构建了一个轮子，那么我们将进行解析通过查找和读取轮子的top_level来获得包的顶级资源。txt文件。这在三分之一的包中是成功的。

***B. 动态分析***

&emsp;&emsp;有些包可能没有正确地列出它们的依赖项，从而阻止pip在安装期间自动处理解析。我们使用SourceRank从库中获得的10,000个包，通过执行动态分析来解决这个问题。输入输出数据。首先，我们尝试使用pip install <package>安装每个包。如果安装成功，则解析顶级资源并尝试导入每个资源。安装/导入过程的任何错误输出都会被记录下来，在出现错误时，我们将解析下列模式实例的输出，这些模式表示依赖于某个不存在的Python包。
 * no module named <name>.
 * pip install <name>.
 * cannot find <name>.
 * cannot import name <name>.

&emsp;&emsp;例如，尝试安装Python包PyHum([14])会得到以下输出:根据输出，我们的动态分析过程将一个依赖记录输入到知识库中，这表明PyHum需要numpy。

&emsp;&emsp;
&emsp;&emsp;
&emsp;&emsp;
&emsp;&emsp;
&emsp;&emsp;
&emsp;&emsp;

## 5 知识表示

## 6 推断算法

## 7 评价

## 8 讨论与展望

## 9 先关工作

## 10 总结
